{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T33srMX8xcmY",
        "outputId": "9254c0a3-fd7d-4b0a-b6a0-ed6294fd2a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n",
        "## Local Inference on GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading necessaary libraries\n",
        "import os\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import torch"
      ],
      "metadata": {
        "id": "PJTO6LkqAUhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/google/efficientnet-b3)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè\n",
        "\n",
        "Model page: https://huggingface.co/google/efficientnet-b3"
      ],
      "metadata": {
        "id": "uQFPgTdH0WKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"image-classification\", model=\"google/efficientnet-b3\")\n",
        "pipe(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png\")\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"google/efficientnet-b3\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"google/efficientnet-b3\")\n",
        "\n",
        "\n",
        "# Load model directly\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
        "\n",
        "processor = EfficientNetImageProcessor.from_pretrained(\"google/efficientnet-b3\")\n",
        "model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b3\")"
      ],
      "metadata": {
        "id": "GNj_DCbd0UYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version of dataset\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkeWi6E3cfM",
        "outputId": "9803b434-de33-4814-fc2e-29b725060dda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fer2013' dataset.\n",
            "Path to dataset files: /kaggle/input/fer2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files_in_dir = os.listdir(path)\n",
        "\n",
        "print(\"Files in the directory:\")\n",
        "for file in files_in_dir:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF5jM7xy3hQE",
        "outputId": "b3dea793-3e18-4811-80eb-f67c67813202"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the directory:\n",
            "test\n",
            "train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in the kaggle directory we have test and train values"
      ],
      "metadata": {
        "id": "PwvNQWtn4t57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will utilize PyTorch ImageFolder library to load our data"
      ],
      "metadata": {
        "id": "ajYO_JJF5Xex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(\n",
        "    mean=processor.image_mean,\n",
        "    std=processor.image_std\n",
        ")\n",
        "# EfficientNet-B3 expects a specific input size (300x300x3)\n",
        "target_size = processor.size['height']\n",
        "\n",
        "# Define the full transformation pipeline for the training set\n",
        "train_transforms = transforms.Compose([\n",
        "    # Resize to the model's required input size\n",
        "    transforms.Resize((target_size, target_size)),\n",
        "    # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.ToTensor(),\n",
        "    # Apply the normalization (using ImageNet stats on which the model was originally trained)\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Define the full transformation pipeline for the test/validation set (similar but might skip augmentation)\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((target_size, target_size)),\n",
        "    # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])"
      ],
      "metadata": {
        "id": "LpeshI7lGMMS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNSTmpMaIs0e",
        "outputId": "f6799056-4029-4f5c-8e2d-227de5e03fc0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# train_dataset = ImageFolder(root='/kaggle/input/fer2013/train')\n",
        "\n",
        "# test_dataset = ImageFolder(root='/kaggle/input/fer2013/test')\n",
        "\n",
        "\n",
        "# Load the datasets with the defined transformations\n",
        "\n",
        "full_train_dataset = ImageFolder(\n",
        "    root=os.path.join(path, 'train'),\n",
        "    transform=train_transforms # Apply the transformation pipeline on the training data\n",
        ")\n",
        "\n",
        "test_dataset = ImageFolder(\n",
        "    root=os.path.join(path, 'test'),\n",
        "    transform=val_test_transforms\n",
        ")\n",
        "\n",
        "# Get class names (sanity check)\n",
        "class_names = full_train_dataset.classes\n",
        "print(f\"Detected class names (7 categories): {class_names}\")\n",
        "# Expected: ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSMEljzZ5fUj",
        "outputId": "c2cb11e3-004a-4245-a535-e9943f3d93de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected class names (7 categories): ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into Train and Validation sets\n",
        "VAL_SPLIT_RATIO = 0.1 # Use 10% of the training data for validation\n",
        "\n",
        "train_size = int((1 - VAL_SPLIT_RATIO) * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_train_dataset,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42) # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Total training samples: {len(full_train_dataset)}\")\n",
        "print(f\"Actual Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccAnlz08OHbm",
        "outputId": "2dd069bb-7cb4-4085-b142-f10efc643edc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 28709\n",
            "Actual Training samples: 25838\n",
            "Validation samples: 2871\n",
            "Test samples: 7178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "\n",
        "# Adjust based on GPU memory\n",
        "BATCH_SIZE = 64  # @param {type: \"slider\", min:30, max:100}\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, # Shuffle training data\n",
        "    num_workers=2  # Use multiple processes for faster loading\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Sanity check the first batch\n",
        "data_batch, labels_batch = next(iter(train_loader))\n",
        "print(\"\\n--- First Batch Sanity Check ---\")\n",
        "print(f\"Batch Tensor Shape: {data_batch.shape}\")\n",
        "print(f\"Label Tensor Shape: {labels_batch.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpNFWffrSiG4",
        "outputId": "84df64e9-3cce-4abf-9298-c6b3a3cd053a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- First Batch Sanity Check ---\n",
            "Batch Tensor Shape: torch.Size([64, 3, 300, 300])\n",
            "Label Tensor Shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimension explanations:\n",
        "\n",
        "64 - Batch size\n",
        "\n",
        "3 - RGB color dimensions\n",
        "\n",
        "300 - x pixel dimension\n",
        "\n",
        "300 - y pixel dimension"
      ],
      "metadata": {
        "id": "9NNvkztlUisk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for GPU availability and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device set to use {device}\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# For multi-class classification, CrossEntropyLoss is common.\n",
        "# Note: EfficientNetForImageClassification typically outputs logits, so CrossEntropyLoss is appropriate.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) # You might want to tune the learning rate\n",
        "\n",
        "epochs = 40  # @param {type: \"slider\", min:10, max:100}\n",
        "\n",
        "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_train_loss = 0\n",
        "    correct_train_predictions = 0\n",
        "    total_train_samples = 0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Zero the gradients\n",
        "        outputs = model(inputs).logits # Get logits from the model output\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward() # Backpropagation\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train_samples += labels.size(0)\n",
        "        correct_train_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_accuracy = correct_train_predictions / total_train_samples\n",
        "    history[\"train_loss\"].append(avg_train_loss)\n",
        "    history[\"train_acc\"].append(train_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_val_loss = 0\n",
        "    correct_val_predictions = 0\n",
        "    total_val_samples = 0\n",
        "\n",
        "    with torch.no_grad(): # No gradient calculations in validation\n",
        "        for inputs, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).logits\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val_samples += labels.size(0)\n",
        "            correct_val_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_accuracy = correct_val_predictions / total_val_samples\n",
        "    history[\"val_loss\"].append(avg_val_loss)\n",
        "    history[\"val_acc\"].append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "NRcCqTQLUScT",
        "outputId": "717029e2-e3dc-4ef1-db6e-ec767ad303e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2807602870.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Device set to use {device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Define loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Evaluation on test set after training\n",
        "# model.eval()\n",
        "# correct_test_predictions = 0\n",
        "# total_test_samples = 0\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         outputs = model(inputs).logits\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total_test_samples += labels.size(0)\n",
        "#         correct_test_predictions += (predicted == labels).sum().item()\n",
        "# test_accuracy = correct_test_predictions / total_test_samples\n",
        "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "6jfoFRQhZywE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}